{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.994327990135635,
  "eval_steps": 500,
  "global_step": 1518,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.09864364981504316,
      "grad_norm": 4.444618225097656,
      "learning_rate": 9.8e-05,
      "loss": 3.1233,
      "step": 50
    },
    {
      "epoch": 0.19728729963008632,
      "grad_norm": 3.5364272594451904,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.1144,
      "step": 100
    },
    {
      "epoch": 0.2959309494451295,
      "grad_norm": 3.267072916030884,
      "learning_rate": 0.00019308885754583922,
      "loss": 1.9393,
      "step": 150
    },
    {
      "epoch": 0.39457459926017263,
      "grad_norm": 2.795301914215088,
      "learning_rate": 0.00018603667136812412,
      "loss": 1.8666,
      "step": 200
    },
    {
      "epoch": 0.4932182490752158,
      "grad_norm": 2.914396047592163,
      "learning_rate": 0.00017898448519040904,
      "loss": 1.854,
      "step": 250
    },
    {
      "epoch": 0.591861898890259,
      "grad_norm": 2.8445427417755127,
      "learning_rate": 0.00017193229901269394,
      "loss": 1.7979,
      "step": 300
    },
    {
      "epoch": 0.6905055487053021,
      "grad_norm": 3.0706918239593506,
      "learning_rate": 0.00016488011283497886,
      "loss": 1.7999,
      "step": 350
    },
    {
      "epoch": 0.7891491985203453,
      "grad_norm": 2.338848114013672,
      "learning_rate": 0.00015782792665726376,
      "loss": 1.7517,
      "step": 400
    },
    {
      "epoch": 0.8877928483353884,
      "grad_norm": 2.9078660011291504,
      "learning_rate": 0.00015077574047954868,
      "loss": 1.6958,
      "step": 450
    },
    {
      "epoch": 0.9864364981504316,
      "grad_norm": 2.8156204223632812,
      "learning_rate": 0.00014372355430183358,
      "loss": 1.7248,
      "step": 500
    },
    {
      "epoch": 1.0848335388409371,
      "grad_norm": 2.8059725761413574,
      "learning_rate": 0.0001366713681241185,
      "loss": 1.5769,
      "step": 550
    },
    {
      "epoch": 1.1834771886559803,
      "grad_norm": 3.17270827293396,
      "learning_rate": 0.0001296191819464034,
      "loss": 1.5277,
      "step": 600
    },
    {
      "epoch": 1.2821208384710234,
      "grad_norm": 3.2091660499572754,
      "learning_rate": 0.0001225669957686883,
      "loss": 1.5344,
      "step": 650
    },
    {
      "epoch": 1.3807644882860666,
      "grad_norm": 3.2614145278930664,
      "learning_rate": 0.0001155148095909732,
      "loss": 1.5175,
      "step": 700
    },
    {
      "epoch": 1.4794081381011097,
      "grad_norm": 2.8209786415100098,
      "learning_rate": 0.00010846262341325813,
      "loss": 1.4976,
      "step": 750
    },
    {
      "epoch": 1.5780517879161529,
      "grad_norm": 2.849452495574951,
      "learning_rate": 0.00010141043723554303,
      "loss": 1.4731,
      "step": 800
    },
    {
      "epoch": 1.676695437731196,
      "grad_norm": 3.4021944999694824,
      "learning_rate": 9.435825105782794e-05,
      "loss": 1.5271,
      "step": 850
    },
    {
      "epoch": 1.7753390875462394,
      "grad_norm": 3.012065887451172,
      "learning_rate": 8.730606488011283e-05,
      "loss": 1.4954,
      "step": 900
    },
    {
      "epoch": 1.8739827373612825,
      "grad_norm": 3.481825590133667,
      "learning_rate": 8.025387870239774e-05,
      "loss": 1.4589,
      "step": 950
    },
    {
      "epoch": 1.9726263871763257,
      "grad_norm": 3.0719168186187744,
      "learning_rate": 7.320169252468265e-05,
      "loss": 1.4817,
      "step": 1000
    },
    {
      "epoch": 2.071023427866831,
      "grad_norm": 3.6201908588409424,
      "learning_rate": 6.614950634696756e-05,
      "loss": 1.332,
      "step": 1050
    },
    {
      "epoch": 2.1696670776818743,
      "grad_norm": 3.129887819290161,
      "learning_rate": 5.9097320169252466e-05,
      "loss": 1.2988,
      "step": 1100
    },
    {
      "epoch": 2.2683107274969174,
      "grad_norm": 3.641187906265259,
      "learning_rate": 5.2045133991537376e-05,
      "loss": 1.3089,
      "step": 1150
    },
    {
      "epoch": 2.3669543773119606,
      "grad_norm": 3.0046334266662598,
      "learning_rate": 4.499294781382229e-05,
      "loss": 1.2982,
      "step": 1200
    },
    {
      "epoch": 2.4655980271270037,
      "grad_norm": 4.127348899841309,
      "learning_rate": 3.7940761636107196e-05,
      "loss": 1.2477,
      "step": 1250
    },
    {
      "epoch": 2.564241676942047,
      "grad_norm": 3.844393491744995,
      "learning_rate": 3.0888575458392106e-05,
      "loss": 1.292,
      "step": 1300
    },
    {
      "epoch": 2.66288532675709,
      "grad_norm": 3.411386728286743,
      "learning_rate": 2.383638928067701e-05,
      "loss": 1.2741,
      "step": 1350
    },
    {
      "epoch": 2.761528976572133,
      "grad_norm": 3.6401379108428955,
      "learning_rate": 1.678420310296192e-05,
      "loss": 1.2792,
      "step": 1400
    },
    {
      "epoch": 2.8601726263871763,
      "grad_norm": 3.812971353530884,
      "learning_rate": 9.732016925246828e-06,
      "loss": 1.2861,
      "step": 1450
    },
    {
      "epoch": 2.9588162762022194,
      "grad_norm": 4.046444416046143,
      "learning_rate": 2.679830747531735e-06,
      "loss": 1.2443,
      "step": 1500
    }
  ],
  "logging_steps": 50,
  "max_steps": 1518,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.801896001466532e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
